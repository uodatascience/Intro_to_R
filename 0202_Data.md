---
title: "2.2 - Data Wrangling"
author: "Jonny Saunders"
date: "10/2/2017"
output: 
  md_document:
    preserve_yaml: true
    toc: true
    toc_depth: 2
order: 3
---

-   [Loading data](#loading-data)
    -   [One day we will have a summary table
        here](#one-day-we-will-have-a-summary-table-here)
    -   [.csv files](#csv-files)
    -   [.sav files](#sav-files)
    -   [`rio` for general import](#rio-for-general-import)
-   [Saving data](#saving-data)
    -   [.RData files](#rdata-files)
    -   [`sink`](#sink)
<<<<<<< HEAD
-   [Stuff to do for 10/19](#stuff-to-do-for-1019)
=======
-   [Indexing](#indexing)
    -   [Logical indexing](#logical-indexing)
    -   [Assignment with Indexing](#assignment-with-indexing)
>>>>>>> 910fefc74c2038e317a06bc7fd764d6d960dbbf3
-   [Manupulating Data](#manupulating-data)
    -   [Wide vs. Long Data](#wide-vs.-long-data)
    -   [Piping syntax](#piping-syntax)
-   [Resources](#resources)

Loading data
============

One day we will have a summary table here
-----------------------------------------

Most of the time we have a datafile (either on our hard drive or on the
internet) that we want to work with in R. To do that, we can use a
function to read the data into R. For instance, the **`read.table()`**
is a flexible function for reading in data in various formats.

.csv files
----------

In order to use **`read.table()`**, you will typically need to specify
some of the arguments, such as the argument **`sep =`**, which is where
you specify the thing that seperates values in your data file.

For example, if you are working with a data file in the comma seperated
values (csv) format, you would need to specify that commas are the
seperator with **`sep = ","`**.

### Defaults

Thankfully, other people have done this for us, and have created
functions that have the proper defaults to work with common formats like
csv fles. For csv files, To see the defaults, simply check the
documentation with e.g. **`?read.table`**

**`read.csv()`** is basically a version of **`read.table()`** with the
defaults set up to work well with csv files. These defaults include
setting **","** as the seperator, and setting **`header = TRUE`**, which
means that R will read in the first row in the csv file as being a
header row, and treat that row as the row of column names. These
defaults can be changed though, so if you had a file with no header, you
would indicate that with **`header = FALSE`**, like so

`read.csv(file_path/file_name.csv, header = FALSE)`

where file\_path is the full path to the file, and file\_name is the
name of the data file. Take a look at the documentation for `read.csv()`
with `?read.csv()` to see the different arguments and defaults.

### A brief interlude into formats for data in R

There are lots of options for reading data into R, even for a single
format.

For example, we could instead use **`read_csv()`** from the **`readr`**
package. The main difference between **`read.csv()`** and
**`read_csv()`** is that they load the data into different formats in R.
**`read.csv()`** will read your data in as a **`data.frame`**, which is
a common format of data in R.

**`read_csv()`** will read your data in as a **`tibble`**, which is the
data format associated with the tidyverse. There are a couple of
differences between these formats. They have different printing
defaults, there are differences in subsetting, and differences in
recycling. Check out the documentation by running the code
**`vignette("tibble")`** or by checking out the chapter on tibbles in
the R for Data Science Book <http://r4ds.had.co.nz/tibbles.html>.

Outside of these differences, they are mostly interchangeable (for most
purposes), but occassionally a function will only work properly with one
or the other. For example, the **`reshape()`** function only works
properly with *data.frames* (unless that has changed in an update).

### Format issues?

In some rare cases, you may be getting an error due to differences
between how your data is formatted in R and what format the function
you're attempting to use works with.

This will sometimes be spelled out in the documentation (e.g.,
**`reshape`** says it takes data frames as the first argument), but its
not always clear; sometimes, you just need to test it out. If you do
need to go between different formats, that is easy to do in R with a
couple of functions. **`as.data.frame()`** will turn an object that can
be a dataframe into a dataframe. **`as_tibble`** will turn an object
that can be a tibble into a tibble.

.sav files
----------

R can also work with datafiles that are formatted for SPSS, which have
the extension '.sav'.

Like csv's, there are a few options. The one that seems to work the best
is **`read_spss()`** from the haven package (also a part of the
tidyverse). There is also a function called **`read.spss()`** from the
**`foreign`** package, but it is no longer being maintained and may stop
working; it also had some frustrating qualities, so probably best to
stick to **`read_spss()`**. It's worth noting that **`read_spss()`**
will format your data as a **`tibble`**. If you don't want it as a
**`tibble`**, you can always use the **`as.data.frame()`** function to
turn it into a generic **`data.frame`**.

`rio` for general import
------------------------

Another function worth knowing about for reading in data is the
**`import()`** function from the **`rio`** package. The nice thing about
**`import()`** is that it works with lots of different types of
datafiles, and very little has to be changed for each type of datafile.
For example, if our data (let's say its name is 'df') were a .sav file,
we would read it in with the following command:

`import(df.sav)`

If it were instead a csv, we would use the following command:

`import(df.csv)`

Note that virtually nothing changed, just the file extension (which is
part of the name of the file). **`import()`** is able to figure out the
format of the file based on that extension.

**Remember to assign your data to a variable in the environment!**

A pretty common and frustrating mistake people make when starting with R
is not saving their data file as an object. For example, if we were
loading in our datafile called 'df', we may want to run some code like
this:

`import(df.csv)`

However, this is telling R to just read the data. If you run code like
that, it will simply read the data, and print out the data (or some
subset of it) into the console. Then, when you go to work with the data,
it won't be in your global environment. That's because you didn't save
it as an object. You would do that the same way you save anything as an
object, with the assignment operator: `<-`. So instead of the above,
you'd instead want to run something like the following:

`df <- import(df.csv)`

Now R has read our data and stored it as an object called `df`, that we
can start running our models on.

Saving data
===========

Most of the above functions have complementary `write` functions, for
example `write.csv` or `haven::write_sav`. There are two other common
ways you may want to save your data

.RData files
------------

Because all objects in R descend from a precious few C structures, they
can all be easily **serialized**, or converted into a string of bits
that can be written to disk (not always true in other languages, like
Python). These files typically can't be read by anything but R (except
if that thing is another programming language where someone has written
a specific routine to do so!), so if your mom tries to look at your cool
data in openoffice they'll be out of luck.

Saving (and loading) .RData files works with the ... `save` and ...
`load` functions

    cant_forget <- c("you have to stop wiping your nose with just whatever is close at hand",
                     "see you did it just now that was mine")
    save(cant_forget, file="cant_forget.RData")

    # Now delete the object so we know our load is real
    rm(cant_forget)

    # here we load to the .GlobalEnv, don't worry we'll cover environments later
    load("cant_forget.RData")
    cant_forget

    ## [1] "you have to stop wiping your nose with just whatever is close at hand"
    ## [2] "see you did it just now that was mine"

Note: as is true of all files, the extension (ending it with 'RData')
doesn't effect the way that a file is saved or represented on the disk,
it just serves to tell the operating system which programs can open it,
and to tell other programs how they should open it. You could just as
easily save your object like

    save(cant_forget, file="cant_forget.butiwantto")

There is one special .RData file, and that's the file that's just called
".RData" in your user directory (for osx `/Users/Username` -- probably
hidden by default). R automatically loads this file every time it opens
-- this is the file that is made whenever you accept RStudio's frequent
offers to save your workspace image.

`save` is also capable of using a few common compression algorithms.
This is most useful for large objects that have many repeated values --
common with "long" format data.

    save(cant_forget, file="cant_forget.RData",
         compress=TRUE, # or "gzip", "bzip2", "xz"
         compression_level=6) # more is smaller, but slower

If you're curious, check out the `saveRDS` function - it's designed to
save single objects (rather than `save`, which can save arbitrary
numbers of objects by keeping them in an environment). Since `save`
saves the object and its environment, when it is loaded it will have the
same name -- this can be troublesome when you have already used that
name, or when you forget what the name is. Loading objects (`readRDS`)
saved by `saveRDS` works like other loading functions, so you can assign
the loaded object to whatver name you'd like.

    saveRDS(cant_forget, file="cant_forget.rds")

    # We can rewrite our fate.
    sad_news <- readRDS("cant_forget.rds")

`sink`
------

Perhaps common is an overstatement. Consider these the option of last
resort when all you want to do is put what you see in this window in
some other window and ya don't care how ya do it.

Any output that would go to the console (specifically to `stdout` - try
`?stdout` - so it's a bit tricky to open a sink in a code chunk) can be
diverted to a file by using the `sink` function. You must call `sink`
with a filename to start diverting data, and then call `sink` again to
stop.

    # Open the sink
    sink("save-everything-here.txt")

    life_story <- c("what we need at the store 2day guys", "it's always just apples and bananas", "we have severe vitamin deficiencies")
    life_story

    ## [1] "what we need at the store 2day guys"
    ## [2] "it's always just apples and bananas"
    ## [3] "we have severe vitamin deficiencies"

    # turn off the sink
    sink()

    # now see what's in our file
    readLines("save-everything-here.txt")

    ## character(0)

`sink` doesn't work with graphical output, to do that we have to use a
function that dumps to a graphics driver, which then saves it as a file.
We can see our current graphics device by getting that option...

    getOption("device")

    ## function (width = 7, height = 7, ...) 
    ## {
    ##     grDevices::pdf(NULL, width, height, ...)
    ## }
    ## <environment: namespace:knitr>

The devices available in the base package are:

-   `pdf()`
-   `postscript()`
-   `xfig()`
-   `bitmap()`
-   `pictex()`

For example

    # make n save a cool plot to show your friends
    pdf("put-plots-here.pdf")
    plot(seq(1,5))
    dev.off()

    ## png 
    ##   2

    # open the pdf however yer system wants to
    abs_path <- file.path(getwd(), "put-plots-here.pdf")
    system2('open', args=abs_path, wait=FALSE)

Notice how we have to use `dev.off()` rather than calling `pdf()` again
as would be expected from `sink`

<<<<<<< HEAD
Stuff to do for 10/19
=====================

-   Indexing (Jonny)
    -   stacking indexing \[\]\[\]\[\]
    -   dplyr::select and variations like contains, one\_of
    -   use of drop (preserving vs simplifying)
    -   sampling
    -   logical indexing & booleans (incl. & vs &&) & converting w/
        which
    -   subsetting with assignment (x\[i\] &lt;- 1)
    -   creating with subsetting (match, using one vector to pull rows
        from a df, doing a gradebook w/ commnets), and destroying
        (unique, dplyr::distinct)
=======
Indexing
========

Or, how to get specific pieces of stuff.

We've already seen a bunch of basic indexing

    # try ?seq
    x <- seq(5, 25, 5)
    x

    ## [1]  5 10 15 20 25

    y <- array(1:24, dim=c(3,8))
    y

    ##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
    ## [1,]    1    4    7   10   13   16   19   22
    ## [2,]    2    5    8   11   14   17   20   23
    ## [3,]    3    6    9   12   15   18   21   24

    z <- list("scores"=c(1,2,3,4,5), 
              "numbers"=c(6,7,8,9,10))

    # good ole positional indexing
    x[3]

    ## [1] 15

    # indexing with a vector to select multiple positions
    x[c(3,5)]

    ## [1] 15 25

    # higher dimensional objects have more dimensions to index
    y[1,5]

    ## [1] 13

    # both together
    y[3, c(3,4,7)]

    ## [1]  9 12 21

    # leaving a position blank selects all of its indices
    y[2,]

    ## [1]  2  5  8 11 14 17 20 23

    # with names
    names(x) <- c("adam", "steve", "harry", "ted", "watson")
    x["harry"]

    ## harry 
    ##    15

    z["numbers"]

    ## $numbers
    ## [1]  6  7  8  9 10

    # Using double brackets to return a vector instead of a list
    z[["numbers"]]

    ## [1]  6  7  8  9 10

    # and the equivalent dollar sign
    z$scores

    ## [1] 1 2 3 4 5

Negative values deselect

    x[-3]

    ##   adam  steve    ted watson 
    ##      5     10     20     25

    # useful to select starting from the end
    -(1:3) # quick way to construct sequences of negative numbers

    ## [1] -1 -2 -3

    x[-(1:3)] # get the last two

    ##    ted watson 
    ##     20     25

We have also seen chained indexing, think of it like indexing the
product of each successive indexing operation

    x[c(1,3,5)][1]

    ## adam 
    ##    5

    z[["numbers"]][4]

    ## [1] 9

    # one reason why it's important what class is returned from your indexing operation
    # aka knowing why we use double brackets
    z["numbers"][4]

    ## $<NA>
    ## NULL

dplyr has a `select` function and a collection of tools ("select
helpers") to make selecting variables by name a bit more flexible:

-   `starts_with()`
-   `ends_with()`
-   `contains()`
-   `matches()` - variables that match a regular expression
-   `num_range()` - eg `num_range("x",1:5)` to select `x1, x2, ...`
-   `one_of()` - find variables in a list, eg.
    `one_of(c("calcium", "potassium", "magnesium"))`
-   `everything()` - all variables, don't know why you'd use this.

A few examples...

    library(dplyr)

    ## 
    ## Attaching package: 'dplyr'

    ## The following objects are masked from 'package:stats':
    ## 
    ##     filter, lag

    ## The following objects are masked from 'package:base':
    ## 
    ##     intersect, setdiff, setequal, union

    df <- ggplot2::diamonds
    names(df)

    ##  [1] "carat"   "cut"     "color"   "clarity" "depth"   "table"   "price"  
    ##  [8] "x"       "y"       "z"

    head(select(df, starts_with("c")))

    ## # A tibble: 6 x 4
    ##   carat       cut color clarity
    ##   <dbl>     <ord> <ord>   <ord>
    ## 1  0.23     Ideal     E     SI2
    ## 2  0.21   Premium     E     SI1
    ## 3  0.23      Good     E     VS1
    ## 4  0.29   Premium     I     VS2
    ## 5  0.31      Good     J     SI2
    ## 6  0.24 Very Good     J    VVS2

    head(select(df, one_of(c("color", "hue", "luminance", "clarity"))))

    ## Warning: Unknown variables: `hue`, `luminance`

    ## # A tibble: 6 x 2
    ##   color clarity
    ##   <ord>   <ord>
    ## 1     E     SI2
    ## 2     E     SI1
    ## 3     E     VS1
    ## 4     I     VS2
    ## 5     J     SI2
    ## 6     J    VVS2

Logical indexing
----------------

In addition to specifying what we want by position, we can specify what
we want by using a vector of booleans (`TRUE`, `FALSE`) the same length
as the object

    x[3]

    ## harry 
    ##    15

    x[c(FALSE, FALSE, TRUE, FALSE, FALSE)]

    ## harry 
    ##    15

This is useful when combined with logical statements (see
`?base::Logic`) and comparisons (see `?Comparison`). One makes logical
statements or comparisons with these operators:

<table>
<thead>
<tr class="header">
<th>Operator</th>
<th>Use</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>!x</code></td>
<td>not x</td>
</tr>
<tr class="even">
<td><code>x &amp; y</code>, <code>x &amp;&amp; y</code></td>
<td>x and y (vectorized, single comparison)</td>
</tr>
<tr class="odd">
<td><code>x | y</code>, <code>x || y</code></td>
<td>x or y (vectorized, single comparison)</td>
</tr>
<tr class="even">
<td><code>xor(x, y)</code></td>
<td>exclusive or (x or y but not both)</td>
</tr>
<tr class="odd">
<td><code>x &lt; y</code></td>
<td>x less than y</td>
</tr>
<tr class="even">
<td><code>x &lt;= y</code></td>
<td>x less than or equal to y</td>
</tr>
<tr class="odd">
<td><code>x &gt; y</code></td>
<td>x greater than y</td>
</tr>
<tr class="even">
<td><code>x &gt;= y</code></td>
<td>x greater than or equal to y</td>
</tr>
<tr class="odd">
<td><code>x == y</code></td>
<td>x is equal to y</td>
</tr>
<tr class="even">
<td><code>x != y</code></td>
<td>x is not equal to y</td>
</tr>
</tbody>
</table>

These will all output boolean vectors, more examples

    x > 10

    ##   adam  steve  harry    ted watson 
    ##  FALSE  FALSE   TRUE   TRUE   TRUE

    x >= 10

    ##   adam  steve  harry    ted watson 
    ##  FALSE   TRUE   TRUE   TRUE   TRUE

    # logical operators can be combined
    (x > 10) & (x < 20)

    ##   adam  steve  harry    ted watson 
    ##  FALSE  FALSE   TRUE  FALSE  FALSE

    # the single & will compare each element
    cbind((x>10), (x<20),((x>10) & (x<20)))

    ##         [,1]  [,2]  [,3]
    ## adam   FALSE  TRUE FALSE
    ## steve  FALSE  TRUE FALSE
    ## harry   TRUE  TRUE  TRUE
    ## ted     TRUE FALSE FALSE
    ## watson  TRUE FALSE FALSE

    # double &&s will only compare the first element - use it when you are trying to evaluate whether a single thing is true or false, eg. is this value greater than one? are my vectors the same length?
    (max(x) > 20) && (min(x) <= 5)

    ## [1] TRUE

This can be used in indexing, either by explicitly referring to the
object within the indexing operator, or by using the `with` function

    # Get all the rows in diamonds who are Good or Very Good
    # remember the comma at the end, we want to select all columns
    df[df$cut=="Good" | df$cut=="Very Good",]

    ## # A tibble: 16,988 x 10
    ##    carat       cut color clarity depth table price     x     y     z
    ##    <dbl>     <ord> <ord>   <ord> <dbl> <dbl> <int> <dbl> <dbl> <dbl>
    ##  1  0.23      Good     E     VS1  56.9    65   327  4.05  4.07  2.31
    ##  2  0.31      Good     J     SI2  63.3    58   335  4.34  4.35  2.75
    ##  3  0.24 Very Good     J    VVS2  62.8    57   336  3.94  3.96  2.48
    ##  4  0.24 Very Good     I    VVS1  62.3    57   336  3.95  3.98  2.47
    ##  5  0.26 Very Good     H     SI1  61.9    55   337  4.07  4.11  2.53
    ##  6  0.23 Very Good     H     VS1  59.4    61   338  4.00  4.05  2.39
    ##  7  0.30      Good     J     SI1  64.0    55   339  4.25  4.28  2.73
    ##  8  0.30      Good     J     SI1  63.4    54   351  4.23  4.29  2.70
    ##  9  0.30      Good     J     SI1  63.8    56   351  4.23  4.26  2.71
    ## 10  0.30 Very Good     J     SI1  62.7    59   351  4.21  4.27  2.66
    ## # ... with 16,978 more rows

    # you can combine boolean vectors arbitrarily

    df[df$cut=="Good" & df$carat>1,]

    ## # A tibble: 1,579 x 10
    ##    carat   cut color clarity depth table price     x     y     z
    ##    <dbl> <ord> <ord>   <ord> <dbl> <dbl> <int> <dbl> <dbl> <dbl>
    ##  1  1.01  Good     I      I1  63.1    57  2844  6.35  6.39  4.02
    ##  2  1.01  Good     H      I1  64.2    61  2846  6.25  6.18  3.99
    ##  3  1.03  Good     J     SI1  63.6    57  2855  6.38  6.29  4.03
    ##  4  1.04  Good     I     SI2  59.9    64  2970  6.51  6.45  3.88
    ##  5  1.01  Good     E      I1  63.8    57  3032  6.40  6.33  4.06
    ##  6  1.02  Good     E      I1  63.1    60  3051  6.31  6.40  4.01
    ##  7  1.01  Good     J     SI2  63.7    60  3088  6.40  6.29  4.05
    ##  8  1.29  Good     I      I1  64.2    54  3098  6.93  6.83  4.42
    ##  9  1.52  Good     E      I1  57.3    58  3105  7.53  7.42  4.28
    ## 10  1.52  Good     E      I1  57.3    58  3105  7.53  7.42  4.28
    ## # ... with 1,569 more rows

    # select columns in the usual way too
    head(df[df$cut=="Good" & df$carat>1, 2])

    ## # A tibble: 6 x 1
    ##     cut
    ##   <ord>
    ## 1  Good
    ## 2  Good
    ## 3  Good
    ## 4  Good
    ## 5  Good
    ## 6  Good

    head(df[df$cut=="Good" & df$carat>1, "color"])

    ## # A tibble: 6 x 1
    ##   color
    ##   <ord>
    ## 1     I
    ## 2     H
    ## 3     J
    ## 4     I
    ## 5     E
    ## 6     E

    head(df[df$cut=="Good" & df$carat>1,]$color)

    ## [1] I H J I E E
    ## Levels: D < E < F < G < H < I < J

    # %in% is a useful way to select multiple levels of a factor
    head(df[df$cut %in% c("Good", "Very Good"),])

    ## # A tibble: 6 x 10
    ##   carat       cut color clarity depth table price     x     y     z
    ##   <dbl>     <ord> <ord>   <ord> <dbl> <dbl> <int> <dbl> <dbl> <dbl>
    ## 1  0.23      Good     E     VS1  56.9    65   327  4.05  4.07  2.31
    ## 2  0.31      Good     J     SI2  63.3    58   335  4.34  4.35  2.75
    ## 3  0.24 Very Good     J    VVS2  62.8    57   336  3.94  3.96  2.48
    ## 4  0.24 Very Good     I    VVS1  62.3    57   336  3.95  3.98  2.47
    ## 5  0.26 Very Good     H     SI1  61.9    55   337  4.07  4.11  2.53
    ## 6  0.23 Very Good     H     VS1  59.4    61   338  4.00  4.05  2.39

    # with temporarily attaches our dataframe so we don't have to keep referring to it explicitly
    head(with(df, df[cut %in% c("Good", "Very Good"),]))

    ## # A tibble: 6 x 10
    ##   carat       cut color clarity depth table price     x     y     z
    ##   <dbl>     <ord> <ord>   <ord> <dbl> <dbl> <int> <dbl> <dbl> <dbl>
    ## 1  0.23      Good     E     VS1  56.9    65   327  4.05  4.07  2.31
    ## 2  0.31      Good     J     SI2  63.3    58   335  4.34  4.35  2.75
    ## 3  0.24 Very Good     J    VVS2  62.8    57   336  3.94  3.96  2.48
    ## 4  0.24 Very Good     I    VVS1  62.3    57   336  3.95  3.98  2.47
    ## 5  0.26 Very Good     H     SI1  61.9    55   337  4.07  4.11  2.53
    ## 6  0.23 Very Good     H     VS1  59.4    61   338  4.00  4.05  2.39

A boolean vector can be converted back to a numerical position vector
with `which`

    x > 10

    ##   adam  steve  harry    ted watson 
    ##  FALSE  FALSE   TRUE   TRUE   TRUE

    which(x > 10)

    ##  harry    ted watson 
    ##      3      4      5

Assignment with Indexing
------------------------

Sometimes we need to change some values in an existing object, but all
assignments to existing objects have to have the same shape and class.
If you give something too small, it will be repeated Rather than having
to create a new object, we can assign to an indexed subset of an object

    friends <- data.frame(names=c("toothbrush", "vacuum", "blinds"),
                          hobbies=c("brushing", "spinning", "darkening"),
                          favorites=c(1,2,3))

    # too small :(
    friends$favorites <- c(4,5)

    ## Error in `$<-.data.frame`(`*tmp*`, favorites, value = c(4, 5)): replacement has 2 rows, data has 3

    # toothbrush and vacuum get a demotion
    friends[c(1,2),]$favorites <- c(4,5)
>>>>>>> 910fefc74c2038e317a06bc7fd764d6d960dbbf3

Manupulating Data
=================

Now that you have your data in R, and have maybe subsetted it in some
manner, you may want to manipulate the data. In this section, we'll
cover some ways that you might want to manipulate data, including
manipulating the format of the data and creating new variables (both
from combining/splitting existing variables, and creating new ones if
you need to).

Wide vs. Long Data
------------------

Let's start by talking about one of the more common data format issues,
which is whether data are structured in a *long* or *wide* format.
These, like basically all things, exist on a continuum (data is almost
always somewhere in between the extremes of long and wide). So, it's
probably helpful to start with an example.

One common design that leads to data easily represented as wide or long
is longitudinal data. Let's say we administer the Big Five Inventory - 2
(BFI-2; Soto & John, 2016) to a sample of incoming freshman annually for
4 years. To keep things simple, let's say we only have that data
(nothing else was administered). In this case, you may have a dataset
that looks like this:

    ## Loading tidyverse: ggplot2
    ## Loading tidyverse: tibble
    ## Loading tidyverse: tidyr
    ## Loading tidyverse: readr
    ## Loading tidyverse: purrr
<<<<<<< HEAD
    ## Loading tidyverse: dplyr
=======
>>>>>>> 910fefc74c2038e317a06bc7fd764d6d960dbbf3

    ## Conflicts with tidy packages ----------------------------------------------

    ## filter(): dplyr, stats
    ## lag():    dplyr, stats

    ## # A tibble: 100 x 21
    ##      pid agreeableness_t1 conscientiousness_t1 neuroticism_t1
    ##    <dbl>            <dbl>                <dbl>          <dbl>
<<<<<<< HEAD
    ##  1     1         2.273893             2.654888       2.935648
    ##  2     2         2.442017             4.002388       4.341911
    ##  3     3         3.003463             3.247350       3.274691
    ##  4     4         2.947982             2.899958       0.817235
    ##  5     5         2.705196             3.705629       3.662651
    ##  6     6         2.351626             3.367753       3.729117
    ##  7     7         2.358903             3.083472       1.109080
    ##  8     8         3.466502             2.471433       2.930717
    ##  9     9         2.474089             2.762298       3.266922
    ## 10    10         2.557933             2.213488       2.750213
=======
    ##  1     1         4.459951             3.752510       3.273738
    ##  2     2         1.465914             4.229048       3.475789
    ##  3     3         2.425646             2.347230       4.041083
    ##  4     4         2.783457             2.805655       1.920559
    ##  5     5         5.205684             3.624008       1.643985
    ##  6     6         2.815984             2.521668       3.557947
    ##  7     7         2.768980             3.310296       4.655732
    ##  8     8         4.789393             2.398198       2.832473
    ##  9     9         2.385962             4.862943       1.734370
    ## 10    10         2.529308             3.007149       3.191462
>>>>>>> 910fefc74c2038e317a06bc7fd764d6d960dbbf3
    ## # ... with 90 more rows, and 17 more variables: extraversion_t1 <dbl>,
    ## #   openness_t1 <dbl>, agreeableness_t2 <dbl>, conscientiousness_t2 <dbl>,
    ## #   neuroticism_t2 <dbl>, extraversion_t2 <dbl>, openness_t2 <dbl>,
    ## #   agreeableness_t3 <dbl>, conscientiousness_t3 <dbl>,
    ## #   neuroticism_t3 <dbl>, extraversion_t3 <dbl>, openness_t3 <dbl>,
    ## #   agreeableness_t4 <dbl>, conscientiousness_t4 <dbl>,
    ## #   neuroticism_t4 <dbl>, extraversion_t4 <dbl>, openness_t4 <dbl>

    ## Classes 'tbl_df', 'tbl' and 'data.frame':    100 obs. of  21 variables:
    ##  $ pid                 : num  1 2 3 4 5 6 7 8 9 10 ...
<<<<<<< HEAD
    ##  $ agreeableness_t1    : num  2.27 2.44 3 2.95 2.71 ...
    ##  $ conscientiousness_t1: num  2.65 4 3.25 2.9 3.71 ...
    ##  $ neuroticism_t1      : num  2.936 4.342 3.275 0.817 3.663 ...
    ##  $ extraversion_t1     : num  2.64 3.53 2.93 1.17 2.51 ...
    ##  $ openness_t1         : num  3.17 3.79 3.38 3.89 3.77 ...
    ##  $ agreeableness_t2    : num  2.68 2.88 3.5 3.42 3.37 ...
    ##  $ conscientiousness_t2: num  2.89 4.3 3.84 3.29 4.27 ...
    ##  $ neuroticism_t2      : num  3.47 4.98 3.69 1.63 4.15 ...
    ##  $ extraversion_t2     : num  2.78 3.85 3.41 1.47 3.21 ...
    ##  $ openness_t2         : num  3.42 4.66 3.5 4.23 4.5 ...
    ##  $ agreeableness_t3    : num  3.36 3.56 4.28 4.08 3.89 ...
    ##  $ conscientiousness_t3: num  3.15 4.77 4.62 3.9 4.82 ...
    ##  $ neuroticism_t3      : num  3.98 5.29 4.12 2.44 4.72 ...
    ##  $ extraversion_t3     : num  2.97 4.64 4.08 2.06 3.77 ...
    ##  $ openness_t3         : num  3.79 5.15 4 4.7 4.91 ...
    ##  $ agreeableness_t4    : num  3.86 4.74 4.66 4.54 4.52 ...
    ##  $ conscientiousness_t4: num  3.77 5.35 4.97 4.39 5.06 ...
    ##  $ neuroticism_t4      : num  4.42 5.77 4.42 3 5.08 ...
    ##  $ extraversion_t4     : num  3.56 4.89 4.27 2.25 4.03 ...
    ##  $ openness_t4         : num  4.11 5.56 4.37 5 5.14 ...
=======
    ##  $ agreeableness_t1    : num  4.46 1.47 2.43 2.78 5.21 ...
    ##  $ conscientiousness_t1: num  3.75 4.23 2.35 2.81 3.62 ...
    ##  $ neuroticism_t1      : num  3.27 3.48 4.04 1.92 1.64 ...
    ##  $ extraversion_t1     : num  4.25 1.96 3.99 3.39 1.97 ...
    ##  $ openness_t1         : num  3.64 4.15 2.9 2.33 3.21 ...
    ##  $ agreeableness_t2    : num  4.95 1.92 2.94 3.17 5.7 ...
    ##  $ conscientiousness_t2: num  4.08 4.99 2.68 3.08 3.88 ...
    ##  $ neuroticism_t2      : num  3.74 3.99 4.78 2.37 2.38 ...
    ##  $ extraversion_t2     : num  4.83 2.17 4.68 3.49 2.57 ...
    ##  $ openness_t2         : num  4.2 4.98 3.16 2.59 3.38 ...
    ##  $ agreeableness_t3    : num  5.65 2.25 3.73 3.99 6.3 ...
    ##  $ conscientiousness_t3: num  4.57 5.68 3.09 3.65 4.51 ...
    ##  $ neuroticism_t3      : num  4.25 4.46 5.41 2.79 2.74 ...
    ##  $ extraversion_t3     : num  5.38 2.57 5.13 3.83 2.91 ...
    ##  $ openness_t3         : num  4.9 5.43 3.62 3.13 3.58 ...
    ##  $ agreeableness_t4    : num  6.3 2.37 4.13 4.33 6.87 ...
    ##  $ conscientiousness_t4: num  5.14 6.07 3.32 3.99 5.28 ...
    ##  $ neuroticism_t4      : num  4.54 5.07 5.85 3.49 3.1 ...
    ##  $ extraversion_t4     : num  6.02 3.32 5.35 4.8 2.93 ...
    ##  $ openness_t4         : num  5.35 6 3.92 3.81 3.86 ...
>>>>>>> 910fefc74c2038e317a06bc7fd764d6d960dbbf3

As you can see in the above, we have a row for each participant, and a
column corresponding to each Big 5 score at each time point. For
example, column 2 contains each participant's score on Agreeableness at
time 1, column 7 contains each participant's score on Agreeableness at
time 2, etc.

This data is in a *wide* format. It's also in basically the widest
format it could be in for any reasonable purpose; the only way to make
it wider would be to have a single row, and a column for each
participant X Big 5 score X time point.

What would make this data *long*? There are two dimensions that we could
lengthen the data on, but the more common one you might see is time.
That is, we'd have a row for each participant X time point combination,
like the following:

    ## # A tibble: 400 x 7
    ##      pid  time agreeableness conscientiousness extraversion neuroticism
    ##  * <dbl> <chr>         <dbl>             <dbl>        <dbl>       <dbl>
<<<<<<< HEAD
    ##  1     1    t1      2.273893          2.654888     2.639601    2.935648
    ##  2     1    t2      2.679415          2.886733     2.775719    3.472118
    ##  3     1    t3      3.357141          3.147073     2.971981    3.977477
    ##  4     1    t4      3.857536          3.770560     3.555359    4.420597
    ##  5     2    t1      2.442017          4.002388     3.533008    4.341911
    ##  6     2    t2      2.878028          4.298398     3.851123    4.980740
    ##  7     2    t3      3.564692          4.770495     4.639021    5.292027
    ##  8     2    t4      4.740486          5.345458     4.894833    5.768292
    ##  9     3    t1      3.003463          3.247350     2.929783    3.274691
    ## 10     3    t2      3.501627          3.838385     3.412991    3.693339
=======
    ##  1     1    t1      4.459951          3.752510     4.246724    3.273738
    ##  2     1    t2      4.948751          4.084644     4.829438    3.736067
    ##  3     1    t3      5.649178          4.573430     5.378654    4.247263
    ##  4     1    t4      6.299802          5.144380     6.015758    4.544044
    ##  5     2    t1      1.465914          4.229048     1.955169    3.475789
    ##  6     2    t2      1.916525          4.986088     2.171944    3.988947
    ##  7     2    t3      2.250886          5.675959     2.569083    4.458365
    ##  8     2    t4      2.373809          6.065085     3.323919    5.067505
    ##  9     3    t1      2.425646          2.347230     3.992819    4.041083
    ## 10     3    t2      2.937126          2.683296     4.684553    4.776825
>>>>>>> 910fefc74c2038e317a06bc7fd764d6d960dbbf3
    ## # ... with 390 more rows, and 1 more variables: openness <dbl>

So we now have a row for each participant at each time point, and a
column for each of the Big 5. We could also make it a little longer, by
making each row correspond to a score on each Big Five trait for each
participant at each time point, like so:

    sample_b5_data_long %>%
      gather(trait, score, agreeableness:openness)

    ## # A tibble: 2,000 x 4
    ##      pid  time         trait    score
    ##    <dbl> <chr>         <chr>    <dbl>
<<<<<<< HEAD
    ##  1     1    t1 agreeableness 2.273893
    ##  2     1    t2 agreeableness 2.679415
    ##  3     1    t3 agreeableness 3.357141
    ##  4     1    t4 agreeableness 3.857536
    ##  5     2    t1 agreeableness 2.442017
    ##  6     2    t2 agreeableness 2.878028
    ##  7     2    t3 agreeableness 3.564692
    ##  8     2    t4 agreeableness 4.740486
    ##  9     3    t1 agreeableness 3.003463
    ## 10     3    t2 agreeableness 3.501627
=======
    ##  1     1    t1 agreeableness 4.459951
    ##  2     1    t2 agreeableness 4.948751
    ##  3     1    t3 agreeableness 5.649178
    ##  4     1    t4 agreeableness 6.299802
    ##  5     2    t1 agreeableness 1.465914
    ##  6     2    t2 agreeableness 1.916525
    ##  7     2    t3 agreeableness 2.250886
    ##  8     2    t4 agreeableness 2.373809
    ##  9     3    t1 agreeableness 2.425646
    ## 10     3    t2 agreeableness 2.937126
>>>>>>> 910fefc74c2038e317a06bc7fd764d6d960dbbf3
    ## # ... with 1,990 more rows

Piping syntax
-------------

<<<<<<< HEAD
Before we get into reshaping data, its importantt we cover a type of
syntax called piping. Piping is not unique to R, but it is highly useful
in R, especially for data wrangling and manipulation. The pipe itself is
this symbol `%>%`, and in R, it comes from the *magrittr* package (this
is a references to the famous painging by Magritte,the treachery of
images). *magrittr* is part of the tidyverse, so it will load when you
call the tidyverse library.

### A quick sidenote about the term pipe

As mentioned above, a pipe in piping syntax is symbolized by `%>%`.
However, another character is sometimes called a pipe, which is the
vertical bar |, and this is used quite a bit in logical/boolean
operations (| means or in logical statements).

### The logic of piping syntax

The general idea of piping syntax, is that we have some function on the
lefthand and righthand side of the pipe. The function on the leftside is
evaluated, and then the **output** of that function is passed to the
function on the righthand side of the pipe as the first argument of that
function. Let's start with a simple example. We'll create a vector of
values and take the mean.

    # first set.seed, because we're going to be sampling values. 
    # this will make it so we always get the same result.
    set.seed(100)
    # first create a vector using rnorm. This is saying give me a random sample of 20 observations, drawn from a normal distribution with a mean of 5 and sd of 1.
    rnorm(n = 20, mean= 5, sd = 1) %>% mean()

    ## [1] 5.107867

As you can see, on the lefthand side of the pipe `%>%`, we have a
function that create a vector of 20 values (sampled from a normal
distribution, with a mean of 5 and an sd of 1). On the righthand side,
we simply have the function mean(), which calculates the mean of a
vector of values. And so what's happening, is first the function on the
righthand side creates a vector; the output of this function is simply
the vector of values:

    set.seed(100)
    rnorm(n=20, mean = 5, sd = 1)

    ##  [1] 4.497808 5.131531 4.921083 5.886785 5.116971 5.318630 4.418209
    ##  [8] 5.714533 4.174741 4.640138 5.089886 5.096274 4.798366 5.739840
    ## [15] 5.123380 4.970683 4.611146 5.510856 4.086186 7.310297

So the output of this fucntion, the vector of 20 values, is then passed
along to the mean function. The mean function requires a vector of
values for its first argument (see for yourself by running `?mean`). So,
we end the pipe with simply `mean()`, and this provides the mean.

#### A quick tip about style

It's typically considered good practice to not have more than one pipe
per line. So what I have above is considered bad coding style. So
instead of

    set.seed(100)
    rnorm(n = 20, mean= 5, sd = 1) %>% mean()

    ## [1] 5.107867

You should instead do this:

    set.seed(100)
    rnorm(n = 20, mean = 5, sd = 1) %>%
      mean()

    ## [1] 5.107867

### Logic of Piping Syntax continued

As we covered above, the function following the pipe takes the output of
the preceding function as its **first** argument. In the preceding
example, we didn't supply another argument, and so the righthand side of
the pipe was simply `mean()`. Let's say, we wanted to specify an
additional argument. One option in `mean()` is trim, which indicates the
proportion of values we want to trim from the vector before calculating
the mean. Let's say we wanted only half the data points; I have no idea
why someone would do something like this, especially with a vector of 20
values, but let's do it anyway.

    set.seed(100)
    # This is the same as before
    rnorm(n = 20, mean = 5, sd = 1) %>%
    # Notice that the mean() function now contains the argument trim = 0.5
        mean(trim = 0.5)

    ## [1] 5.09308

You'll see we got a slightly different value; a value a little closer to
the population mean of 5, since 50% of the values in the tails were
removed from the vectore before calculating the mean.

This can be pretty confusing when you're new to piping, because our
`mean()` function is basically missing an argument, namely, the argument
with the name of the vector of values. Importantly, the argument isn't
missing, it's just sort of hidden under the hood. The `mean()` line
above, to R, is actually looking something like this:
`mean(vector_output_above, trim = 0.5)`, it's just that the first
argument is hidden from view. So, we could do this in two steps, without
pipes.

    set.seed(100)
    # we could create the vectore, and save it as an object
    vector_from_pipe <- rnorm(n = 20, mean = 5, sd = 1)

=======
>>>>>>> 910fefc74c2038e317a06bc7fd764d6d960dbbf3
We'll cover how to reshape

-   Manipulating
    -   Wide v Long data as intro
    -   piping syntax (incl. when to use/not use)
    -   reshaping - gather/melt & spread/dcast
        (<https://www.r-bloggers.com/how-to-reshape-data-in-r-tidyr-vs-reshape2/>)
    -   reordering (incl. reordering factor levels, talking abt factors)
    -   separate & colsplit
    -   combining dataframes (if this makes sense to do/there's time to
        do it) (see relational data in r4ds)
-   Annoyances
    -   dealing with `NaN`s
    -   typing your data (mainly to cover factors, ordered v. unordered)

Resources
=========

-   R Data Import/Export Manual:
    <https://cran.r-project.org/doc/manuals/R-data.pdf>
-   <http://zoonek2.free.fr/UNIX/48_R/02.html#6>
-   <https://www.statmethods.net/interface/io.html>
-   <http://adv-r.had.co.nz/Subsetting.html#applications>
-   <https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf>

<!-- -->

    ## [1] TRUE

    ## [1] TRUE

    ## [1] TRUE

    ## [1] TRUE

    ## [1] TRUE
